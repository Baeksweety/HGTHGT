{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nmslib\n",
    "import networkx as nx\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hnsw:\n",
    "    def __init__(self, space='cosinesimil', index_params=None,\n",
    "                 query_params=None, print_progress=True):\n",
    "        self.space = space\n",
    "        self.index_params = index_params\n",
    "        self.query_params = query_params\n",
    "        self.print_progress = print_progress\n",
    "\n",
    "    def fit(self, X):\n",
    "        index_params = self.index_params\n",
    "        if index_params is None:\n",
    "            index_params = {'M': 16, 'post': 0, 'efConstruction': 400}\n",
    "\n",
    "        query_params = self.query_params\n",
    "        if query_params is None:\n",
    "            query_params = {'ef': 90}\n",
    "\n",
    "        # this is the actual nmslib part, hopefully the syntax should\n",
    "        # be pretty readable, the documentation also has a more verbiage\n",
    "        # introduction: https://nmslib.github.io/nmslib/quickstart.html\n",
    "        index = nmslib.init(space=self.space, method='hnsw')\n",
    "        index.addDataPointBatch(X)\n",
    "        index.createIndex(index_params, print_progress=self.print_progress)\n",
    "        index.setQueryTimeParams(query_params)\n",
    "\n",
    "        self.index_ = index\n",
    "        self.index_params_ = index_params\n",
    "        self.query_params_ = query_params\n",
    "        return self\n",
    "\n",
    "    def query(self, vector, topn):\n",
    "        # the knnQuery returns indices and corresponding distance\n",
    "        # we will throw the distance away for now\n",
    "        indices, dist = self.index_.knnQuery(vector, k=topn)\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data as geomData\n",
    "from itertools import chain\n",
    "\n",
    "def pt2graph(wsi_h5, slidename,radius=9):\n",
    "    from torch_geometric.data import Data as geomData\n",
    "    from itertools import chain\n",
    "    coords, features = np.array(wsi_h5['coords']), np.array(wsi_h5['features'])\n",
    "    assert coords.shape[0] == features.shape[0]\n",
    "    num_patches = coords.shape[0]\n",
    "#     print(num_patches)\n",
    "    superpixel_info_path = os.path.join('/data14/yanhe/miccai/super_pixel/slide_superpixel/argo_new/superpixel_num_500',slidename+'.pth')\n",
    "    superpixel_info = torch.load(superpixel_info_path)\n",
    "    superpixel_attri=[]\n",
    "#     print(len(superpixel_info))\n",
    "    for index in range(len(superpixel_info)):\n",
    "        superpixel = superpixel_info[index]['superpixel']\n",
    "        superpixel_attri.append(superpixel)\n",
    "    superpixel_attri = torch.LongTensor(superpixel_attri)  \n",
    "#     print(superpixel_attri)\n",
    "    \n",
    "    inter_graph_path = os.path.join('/data14/yanhe/miccai/super_pixel/graph_file/argo/superpixel_num_500',slidename+'.pt')\n",
    "    g = torch.load(inter_graph_path)\n",
    "    for index in range(g.ndata['centroid'].shape[0]):\n",
    "        edge_index = torch.Tensor()\n",
    "        edge_index = g.edges()[0].unsqueeze(0)\n",
    "        edge_index = torch.cat((edge_index,g.edges()[1].unsqueeze(0)),dim=0)\n",
    "        \n",
    "    model = Hnsw(space='l2')\n",
    "    model.fit(coords)\n",
    "    a = np.repeat(range(num_patches), radius-1)\n",
    "    b = np.fromiter(chain(*[model.query(coords[v_idx], topn=radius)[1:] for v_idx in range(num_patches)]),dtype=int)\n",
    "    edge_spatial = torch.Tensor(np.stack([a,b])).type(torch.LongTensor)\n",
    "    superpixel_edge = superpixel_attri[edge_spatial]\n",
    "\n",
    "    edge_mask = (superpixel_edge[0,:] == superpixel_edge[1,:])\n",
    "\n",
    "    remain_edge_index = edge_spatial[:,edge_mask]\n",
    "    G = geomData(x = torch.Tensor(features),\n",
    "                 edge_patch = remain_edge_index,\n",
    "                 edge_superpixel = edge_index,\n",
    "                 superpixel_attri = superpixel_attri,\n",
    "                 centroid = torch.Tensor(coords))\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDir_h5toPyG(h5_path, save_path):\n",
    "    pbar = tqdm(os.listdir(h5_path))\n",
    "    for h5_fname in pbar:\n",
    "        pbar.set_description('%s - Creating Graph' % (h5_fname[:-3]))\n",
    "\n",
    "        try:\n",
    "            wsi_h5 = h5py.File(os.path.join(h5_path, h5_fname), \"r\")\n",
    "            slidename = h5_fname[:-3]\n",
    "            if slidename != 'ZS6Y1A01554_HE520' and slidename != 'ZS6Y1A03883_HE208' and slidename != 'ZS6Y1A07240_HE400' and slidename != 'ZS6Y1A08318_HE155':\n",
    "                G = pt2graph(wsi_h5,slidename)\n",
    "                torch.save(G, os.path.join(save_path, h5_fname[:-3]+'.pt'))\n",
    "            wsi_h5.close()\n",
    "        except OSError:\n",
    "            pbar.set_description('%s - Broken H5' % (h5_fname[:12]))\n",
    "            print(h5_fname, 'Broken')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_path = '/data12/ybj/survival/argo_selected/20x/slides_feat/h5_files'\n",
    "save_path = '/data14/yanhe/miccai/graph_file/argo/superpixel_num_500/'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "createDir_h5toPyG(h5_path, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylcx",
   "language": "python",
   "name": "pylcx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
